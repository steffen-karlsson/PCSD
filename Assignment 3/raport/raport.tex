\documentclass[10pt,a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{graphicx}
\newcommand{\folge}[1]{\left \lbrace #1 \right \rbrace }
\lstset{language=Java, numbers=left, numberstyle=\footnotesize}
\author{Thorbj√∏rn Christensen \\
Steffen Karlsson \\
Kai Ejler Rasmussen}
\title{Principles of Computer System Design - Assignment 3}
\begin{document}
\maketitle

\section*{Exercises}
\subsection*{Question 1: Recovery Concepts}
\begin{enumerate}
	\item No Force requires redo because the pages not necessarily have been written to the disk and Steal allows swapping dirty pages from main memory to disk and therefore requires undo. By these assumptions force and no-steal requires neither redo or undo.
	\item Both nonvolatile and stable storage can recover from a crash given that \texttt{ARIES} is implemented, but if a media crash happens, we lose nonvolatile storage. But using stable storage on the other hand, we have a negligible chance of losing the data, because stable storage typically is implemented using RAID-1 or greater or off-site backups.
	\item In a system that implements Write-Ahead Logging, the log tail is forced to stable storage during either commit or page swap. During commit because its the no-force method which requires redo, and second of all the page swap is a steal operation, which as mentioned earlier requires undo. In order to repeat history after a crash or media crash it is necessary to force write the logs to stable storage.
\end{enumerate}

\subsection*{Question 2: ARIES}
\begin{enumerate}
	\item The dirty-page table after the analysis phase looks like following:
		\begin{center}
		\begin{tabular}{|l|l|}
			\hline
			\textbf{pageID} & \textbf{recLSN} \\ \hline
			P2 & 3 \\ \hline
			P1 & 4 \\ \hline
			P5 & 5 \\ \hline
			P3 & 9 \\ \hline
		\end{tabular}
		\end{center}
		, and the transaction table after same state looks like this:
		\begin{center}
		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{transID} & \textbf{lstLSN} & \textbf{status} \\ \hline
			T1 & 4 & U \\ \hline
			T2 & 9 & U \\ \hline
		\end{tabular}
		\end{center}
		, the reason that \texttt{T3} isn't in the transaction table is that the transaction had committed before the crash happened.
	\item All transactions left in the transaction table after the analysis phase is the looser transactions, which means that in our case its \texttt{T1} and \texttt{T2}. Due to this assumption, \texttt{T3} must be the only winner in this case.
	\item The redo phase starts at the smallest \texttt{recLSN} value of all dirty pages in the dirty-page table and therefore is it in this case at value 3. The undo action ends at the same place where the redo action starts. 
	\item
	\item
	\item
\end{enumerate}

\subsection*{Questions for Discussion}
\begin{enumerate}
	\item The two data generating methods, namely \texttt{sampleFromSetOfISBNs} and \texttt{nextSetOfStockBooks}, has mainly been implemented using the build in \texttt{Random} generator from Java. \texttt{sampleFromSetOfISBNs} has been implemented using the \textit{shuffle} method from the Collections interface and then picking a range from \texttt{[0..num]} to return. \texttt{nextSetOfStockBooks} is for each book assigning a new not used ISBN number and other values such as number of copies, price and rating is auto generated - but still ensured to be in range of the acceptable, such that it can pass the sanity checks from \texttt{BookStoreUtility}.
	\newline
	
	To calculate the metrics, average throughput and latency, we have been using the same number of repetitions and configuration in general for all the different number of workers, to be able to compare the results. We have been using following different numbers of concurrent workload threads: \texttt{[1, 3, 5, 10, 20, 30, 50, 75, 100, 150, 250, 500, 1000]}, for each iterating did we calculate the average throughput and latency for each worker and then for all the workers in total.
	\newline
	
	We have been using following hardware to run our tests on: Intel(R) Core(TM) i7-2600 CPU @ 3.40GHz and 8,00 GB Ram.
	\item TODO
	\begin{center}
		\begin{figure}
				\includegraphics[scale=0.5]{latency.png}
				\caption{Plot of average latency using 1 to 1000 concurrent workload threads}
		\end{figure}
		\begin{figure}
				\includegraphics[scale=0.5]{throughput.png}
				\caption{Plot of average throughput using 1 to 1000 concurrent workload threads}
		\end{figure}
	\end{center}
\end{enumerate}
\end{document}